# github-web-scrapping
A simple scraper to collect information of a github repositore

the script will generate reports in txt format for all files in "repositores.txt"
<h4><strong>*</strong> to script work, the file "repositores.txt" must be in the project's root folder</h4>

before executing the script, check if you have all the necessary requirements to execute it, you can install the dependencies through the file "requirements.txt" with <strong>"pip install"</strong> before the execution

to run the script you must open the <strong>terminal</strong> and navigate to the directory where you cloned the repository
and <strong>run</strong>:

in terminal: <strong>"C:\User\Desktop\<folder_where_you_cloned> python get_project_github_info"</strong>
 
you can manipulate the data using the "gitutils" library to create json files for example
